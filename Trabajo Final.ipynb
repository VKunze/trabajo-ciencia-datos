{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</center><img src=\"https://www3.um.edu.uy/logoum.jpg\" width=300></center>\n",
    "<h1 align=\"center\">Introducción a la Ciencia de Datos</h1>\n",
    "<h2 align=\"center\"> <font color='gray'>Trabajo Final</font></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import itertools\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data.csv')\n",
    "data.head(10)\n",
    "\n",
    "clean_data = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The max (98) and min (17) ages are within normal ranges\n"
     ]
    }
   ],
   "source": [
    "max = data['age'].max()\n",
    "min = data['age'].min()\n",
    "print(f'The max ({max}) and min ({min}) ages are within normal ranges')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Age distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ages = data['age']\n",
    "range = [0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "#plt.figure(figsize=(7,3))\n",
    "#sns.set()\n",
    "#plt.hist(ages, bins=range)\n",
    "#plt.title(label=\"Age distribution\", fontsize=25)\n",
    "#plt.xticks(range)\n",
    "#plt.xlabel('Ages', fontsize=15)\n",
    "#plt.ylabel('Amount of people', fontsize=15)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorica nominal \n",
    "(cuantas categorias hay?, una col por categoria + top k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = data['job'].value_counts()\n",
    "#print(count)\n",
    "categories = data['job'].unique()\n",
    "#print(\"amount: \", len(categories))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay 246 datos faltantes. Creo que en este caso no tiene sentido imputarlos por valores parecidos (Hot deck), porque no hay datos de cuanto ganan ni nada que sea especifico de los trabajos.\n",
    "Podemos imputarlo aleatoriamente.\n",
    "\n",
    "Otra cosa: como podemos capaz juntarlos en categorías para disminuir en cols. Ej:\n",
    "- entrepreneur + self-employed \n",
    "- admin. + management\n",
    "- blue-collar\n",
    "- technician + services\n",
    "- retired + unemployed + student   \n",
    "- housemaid "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  5,  7,  6,  4,  9,  2,  3, 10, 11,  8])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "clean_data['job'] = label_encoder.fit_transform(data['job'])\n",
    "clean_data['job'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing data imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = clean_data.corr(method ='spearman')\n",
    "#lista = [corr_matrix['job']>0.3]\n",
    "#lista"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As there is no correlation between the job and any other variable, we are going to impute these values at random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "data['job'] = data['job'].replace(\"unknown\", np.nan)\n",
    "data['job'] = data['job'].fillna(random.choice(data['job'].values.tolist()))\n",
    "#data['job'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  5,  7,  6,  4,  9,  2,  3, 10, 11,  8], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "clean_data['job'] = label_encoder.fit_transform(data['job'])\n",
    "clean_data['job'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Marital"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data is a categorical and nominal kind of data, there are 3 possible values: 'single', 'married' and 'divorced'.<br>\n",
    "We assigned 1-single 2-married 3-divorced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data['marital'] = clean_data['marital'].replace('single',1)\n",
    "clean_data['marital'] = clean_data['marital'].replace('married',2)\n",
    "clean_data['marital'] = clean_data['marital'].replace('divorced',3)\n",
    "clean_data['marital'] = clean_data['marital'].replace('unknown',4)\n",
    "clean_data.loc[clean_data['marital']==4].count().mean() #faltantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's possible that unkwnown values depend on the column itself, in that case they would be MNAT.\n",
    "In order to imputate those values we will use domain knowledge. The most probable value to not want to tell their marital state is 'divorced', we will imputate unkwown values as 'divorced'.\n",
    "Reference: https://towardsdatascience.com/uncovering-missing-not-at-random-data-8d2cd3eda31a#:~:text=The%20only%20true%20way%20to,and%20get%20the%20key%20information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data['marital'] = clean_data['marital'].replace('unknown',3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean_data.head(3)\n",
    "#clean_data['marital'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Education\n",
    "This data is caterogircal an ordinal kin d of data. There are 7 possible values: 'university.degree', 'professional.course', 'high.school', 'basic.9y', 'basic.6y', 'basic.4y', 'illiterate' and 'unknown'.  <br>\n",
    "The feature engineering approach is to generate an ordinal encoding scheme for mapping each category to a numeric value by leveraging scikit-learn.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "edu_count = data['education'].value_counts()\n",
    "#edu_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['university.degree', 'basic.4y', 'high.school', 'basic.9y',\n",
       "       'unknown', 'professional.course', 'basic.6y', 'illiterate'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['education'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method used to imputate data is hot-deck imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "edu_dict = { 'university.degree' : 7,\n",
    "             'professional.course' : 6,\n",
    "             'high.school' : 5,\n",
    "             'basic.9y': 4,\n",
    "             'basic.6y' : 3, \n",
    "             'basic.4y' : 2,\n",
    "             'illiterate' : 1}\n",
    "clean_data['education'] = clean_data.education.map(edu_dict)\n",
    "#clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.impute import KNNImputer\n",
    "imputer = KNNImputer(missing_values=np.nan, n_neighbors=2, weights=\"uniform\")\n",
    "clean_data['education'] = imputer.fit_transform(clean_data[['education']])\n",
    "#clean_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7., 2., 5., 4., 6., 3., 1.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data['education'] = np.where((clean_data['education'] > 5) & (clean_data['education'] < 6), 5,clean_data['education'])\n",
    "clean_data['education'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no         26074\n",
       "unknown     6875\n",
       "yes            1\n",
       "Name: default, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cant = data['default'].value_counts()\n",
    "cant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "default = [cant['yes'], cant['no'], cant['unknown']]\n",
    "c = ( \"green\", \"blue\", \"orange\") \n",
    "props = { 'linewidth' : 1, 'edgecolor' : \"black\" } \n",
    "  \n",
    "#fig, ax = plt.subplots(figsize =(15, 10)) \n",
    "#wedges, autotexts, texts = ax.pie(default, labels = ['yes', 'no', 'unknown'], colors = c, startangle = 90,wedgeprops = props, autopct='%.2f', textprops = dict(color =\"white\", weight='bold', size = 12))\n",
    "  \n",
    "#ax.legend(wedges, default, title =\"Default\", loc =\"center left\", bbox_to_anchor =(1.5, 0, 1.5, 1)) \n",
    "  \n",
    "#plt.setp(autotexts, color='black') \n",
    "#ax.set_title(\"Default\", fontsize=25, weight='bold') \n",
    "  \n",
    "#plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "gle = LabelEncoder()\n",
    "labels = gle.fit_transform(data['default'])\n",
    "mappings = {index: label for index, label in enumerate(gle.classes_)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data['default_labels'] = labels\n",
    "#data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean_data.corr(method ='pearson') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Housing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data is a categorical and nominal kind of data, there are 3 possible values: 'yes', 'no' and 'unknown'. <br>\n",
    "The feature engineering approach is to generate a label encoding scheme for mapping each category to a numeric value by leveraging scikit-learn.<br>\n",
    "Reference: https://towardsdatascience.com/understanding-feature-engineering-part-2-categorical-data-f54324193e63"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "yes        17292\n",
       "no         14869\n",
       "unknown      789\n",
       "Name: housing, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = data['housing'].value_counts()\n",
    "count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are only 3 possible values and the distribution between them is withing normal ranges, we don't have outliers. However, we need to imputate the unknown values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Housing debt distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = [count['yes'], count['no'], count['unknown']]\n",
    "explode = (0.05, 0.05, 0.05) \n",
    "colors = ( \"#003f5c\", \"#bc5090\", \"#ffa600\") \n",
    "#wp = { 'linewidth' : 1, 'edgecolor' : \"black\" } \n",
    "  \n",
    "#fig, ax = plt.subplots(figsize =(15, 10)) \n",
    "#wedges, autotexts, texts = ax.pie(housing, explode = explode, labels = ['yes', 'no', 'unknown'], \n",
    "#                           shadow = True, colors = colors, startangle = 90,\n",
    "#                           wedgeprops = wp, autopct='%.2f', \n",
    "#                           textprops = dict(color =\"white\", weight='bold', size = 15))\n",
    " \n",
    "#ax.legend(wedges, housing, \n",
    "#          title =\"Has housing debt?\", \n",
    "#          loc =\"center left\", \n",
    "#          bbox_to_anchor =(1, 0, 1.5, 1)) \n",
    "  \n",
    "#plt.setp(autotexts, color='black') \n",
    "#ax.set_title(\"Housing distribution\", fontsize=25, weight='bold') \n",
    " \n",
    "#show plot \n",
    "#plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'no', 1: 'unknown', 2: 'yes'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "gle = LabelEncoder()\n",
    "labels = gle.fit_transform(data['default'])\n",
    "mappings = {index: label for index, label in \n",
    "                  enumerate(gle.classes_)}\n",
    "mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data['housing'] = labels\n",
    "#clean_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:253: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  res_values = method(rvalues)\n"
     ]
    }
   ],
   "source": [
    "filtered_data = clean_data[clean_data['marital'] != 'unknown']\n",
    "#filtered_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>housing</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>housing</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.186809</td>\n",
       "      <td>0.186776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.186809</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.186776</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          housing         0         1\n",
       "housing  1.000000  0.186809  0.186776\n",
       "0        0.186809  1.000000  0.999983\n",
       "1        0.186776  0.999983  1.000000"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Check if housing is correlated to the combination of age and job or age, job and marital.\n",
    "\n",
    "age_job = (filtered_data['age'].astype(str) + filtered_data['job'].astype(str)).astype(int)\n",
    "age_job_marital = (filtered_data['age'].astype(str) + filtered_data['job'].astype(str) + filtered_data['marital'].astype(str)).astype(int)\n",
    "test_df = pd.concat([filtered_data['housing'], age_job, age_job_marital],  axis=1, ignore_index=False)\n",
    "test_df.head()\n",
    "test_df.corr(method='spearman')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing data imputation\n",
    "We consider that this variable is missingness depending on the value itself, because noone wants to admit over the phone that they have a loan. Therefore we are going to impute the missing values all as \"yes\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data[\"housing\"] = clean_data[\"housing\"].replace(1, 2)\n",
    "clean_data[\"housing\"] = clean_data[\"housing\"].replace(2, 1)\n",
    "clean_data[\"housing\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "binaria, faltantes (?) - evaluar correlacion con otras columnas (trabajo, edad) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no         27196\n",
      "yes         4965\n",
      "unknown      789\n",
      "Name: loan, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "count = data['loan'].value_counts()\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing data imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the same argument as before, we will impute the value yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['no', 'yes'], dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data[\"loan\"] = data[\"loan\"].replace('unknown', 'yes')\n",
    "clean_data[\"loan\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = pd.concat([clean_data, pd.get_dummies(data['loan'], prefix='loan', drop_first = True)], axis=1)\n",
    "#clean_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform to binary 0-cellular 1-telephone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data['contact'] = clean_data['contact'].replace('cellular',0)\n",
    "clean_data['contact'] = clean_data['contact'].replace('telephone',1)\n",
    "#clean_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = pd.concat([clean_data, pd.get_dummies(data['loan'], prefix='loan', drop_first = True)], axis=1)\n",
    "#clean_data.drop(columns='loan')\n",
    "#clean_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_count = data['month'].value_counts()\n",
    "#month_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_dict = { 'jan' : 1,\n",
    "               'feb' : 2,\n",
    "               'mar' : 3,\n",
    "               'apr': 4,\n",
    "               'may' : 5, \n",
    "               'jun' : 6,\n",
    "               'jul' : 7,\n",
    "               'aug' : 8,\n",
    "               'sep' : 9,\n",
    "               'oct' : 10,\n",
    "               'nov' : 11,\n",
    "               'dec' : 12}\n",
    "clean_data['month_ordinal_label'] = data.month.map(month_dict)\n",
    "#data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# day_of_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['tue', 'wed', 'mon', 'fri', 'thu'], dtype=object)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data.day_of_week.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertir(day_of_week):\n",
    "    if day_of_week == 'mon':\n",
    "        return 0\n",
    "    elif day_of_week == 'tue':\n",
    "        return 1\n",
    "    elif day_of_week == 'wed':\n",
    "        return 2\n",
    "    elif day_of_week == 'thu':\n",
    "        return 3\n",
    "    elif day_of_week == 'fri':\n",
    "        return 4\n",
    "clean_data[\"day_of_week\"] = data[\"day_of_week\"].apply(convertir)\n",
    "#clean_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This indicates the duration of the last call, in seconds. It is a numerical tyoe of data, with wide ranges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "durations = data['duration']\n",
    "range = np.arange(0, 5000, 100)\n",
    "#plt.figure(figsize=(15,8))\n",
    "#sns.set()\n",
    "#plt.hist(durations, bins=100)\n",
    "#plt.title(label=\"Call duration distribution\", fontsize=25)\n",
    "#plt.xticks(range, rotation=90)\n",
    "#plt.xlabel('Durations', fontsize=15)\n",
    "#plt.ylabel('Amount of calls', fontsize=15)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that we have outliers for the calls that last more than 1600 seconds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outliers analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    32950.000000\n",
       "mean       257.240728\n",
       "std        257.171015\n",
       "min          0.000000\n",
       "25%        103.000000\n",
       "50%        180.000000\n",
       "75%        319.000000\n",
       "max       4918.000000\n",
       "Name: duration, dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['duration'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(15,8))\n",
    "#plt.title('Box plot - outlier detection', fontsize=15)\n",
    "#plt.boxplot(data['duration'])\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the describe function and the box plot is clear that the higher numbers are likely to be outliers. The Pearson correlation doesn't indicate a relation between the call duration and the other measured values, we can assume that this outliers won't bias out data because they seem to be caused completely at random."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The selected approach will be to do data binning for two main reasons:\n",
    "- Using the individual call durations has no utility for the analysis\n",
    "- We can treat the outliers and fit them into the top or lower bins\n",
    "<br>\n",
    "<br>\n",
    "We will use equal width binning, it tries to divide up the underlying data into equal sized bins.\n",
    "The qcut function from pandas will be used, it defines the bins using percentiles based on the distribution of the data, not the actual numeric edges of the bins.<br>\n",
    "Reference: https://pbpython.com/pandas-qcut-cut.html, https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.qcut.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bins = pd.qcut(data['duration'], q=10)\n",
    "#bins.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(546.0, 4918.0], (59.0, 88.0], (117.0, 146.0], (-0.001, 59.0], (279.0, 367.0], (88.0, 117.0], (367.0, 546.0], (221.0, 279.0], (146.0, 180.0], (180.0, 221.0]]\n",
       "Categories (10, interval[float64]): [(-0.001, 59.0] < (59.0, 88.0] < (88.0, 117.0] < (117.0, 146.0] ... (221.0, 279.0] < (279.0, 367.0] < (367.0, 546.0] < (546.0, 4918.0]]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bins.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data['duration'] = pd.qcut(data['duration'], q=10, labels=False)\n",
    "#clean_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Campaign"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "número de contactos realizados durante esta campaña y para este cliente -> solo evaluar si hay outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    32950.000000\n",
       "mean         2.571411\n",
       "std          2.784660\n",
       "min          1.000000\n",
       "25%          1.000000\n",
       "50%          2.000000\n",
       "75%          3.000000\n",
       "max         56.000000\n",
       "Name: campaign, dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['campaign'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "amount_campaign = data['campaign']\n",
    "range = np.arange(1, 60, 1)\n",
    "#plt.figure(figsize=(15,8))\n",
    "#sns.set()\n",
    "#plt.hist(amount_campaign, bins=60)\n",
    "#plt.title(label=\"Amount of contacts during campaign distribution\", fontsize=25)\n",
    "#plt.xticks(range, rotation=90)\n",
    "#plt.xlabel('Amount of contacts', fontsize=15)\n",
    "#plt.ylabel('Clients', fontsize=15)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to this distribution we are going to use a top-coding to normalize the data. \n",
    "\n",
    "#### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_code = data['campaign'].quantile(0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def campaign_top_coding(value):\n",
    "    if(value > top_code + 1):\n",
    "        return top_code + 1\n",
    "    else:\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    14200\n",
       "2.0     8391\n",
       "4.0     6126\n",
       "3.0     4233\n",
       "Name: campaign, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data['campaign'] = data['campaign'].apply(campaign_top_coding)\n",
    "clean_data['campaign'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pdays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Número de días que pasaron desde la última vez que se contactó con el cliente desde una campaña anterior.\n",
    "Los dividimos en dos categorías 0-Se contactó al cliente recientemente(0-27 días) 1-No se ha contactado al cliente desde la campaña anterior (999 días)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data['pdays'] = clean_data['pdays'].replace([0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27],0)\n",
    "clean_data['pdays'] = clean_data['pdays'].replace(999,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Previous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    28443\n",
       "1     3642\n",
       "2      609\n",
       "3      179\n",
       "4       57\n",
       "5       15\n",
       "6        4\n",
       "7        1\n",
       "Name: previous, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previous_count = data['previous'].value_counts()\n",
    "previous_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_code = data['previous'].quantile(0.9)\n",
    "top_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def previous_top_coding(value):\n",
    "    if(value > top_code + 1):\n",
    "        return top_code + 1\n",
    "    else:\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    28443\n",
       "1.0     3642\n",
       "2.0      865\n",
       "Name: previous, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data['previous'] = data['previous'].apply(previous_top_coding)\n",
    "clean_data['previous'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
